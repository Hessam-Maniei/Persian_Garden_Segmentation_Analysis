{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c1962f6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc58bd59",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e303e23",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "004fc011",
   "metadata": {},
   "source": [
    "# Semantic Segmentation of Persian Garden Images\n",
    "## Case Study: Fin Garden, Kashan\n",
    "\n",
    "This notebook implements a semantic segmentation pipeline using a U-Net\n",
    "architecture (PyTorch) for Persian garden images.\n",
    "\n",
    "The dataset consists of RGB images and RGB-encoded segmentation masks\n",
    "annotated in Roboflow.\n",
    "\n",
    "Classes:\n",
    "- Trees\n",
    "- Buildings\n",
    "- Sky\n",
    "- Steps\n",
    "- Cover Plants\n",
    "- Water\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3523116f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/hessam/Documents/GitHub/Persian_Garden_Segmentation_Analysis/venv/bin/python'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141ca5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hessam/Documents/GitHub/Persian_Garden_Segmentation_Analysis/venv/lib/python3.12/site-packages/albumentations/check_version.py:147: UserWarning: Error fetching version info <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)>\n",
      "  data = fetch_version_info()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Environment & Import libraries\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "727740a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: 0\n",
      "Masks : 0\n"
     ]
    }
   ],
   "source": [
    "# Paths & file pairing\n",
    "IMAGE_DIR = \"/Users/hessam/Documents/GitHub/Persian_Garden_Segmentation_Analysis/Data/image\"\n",
    "MASK_DIR = \"/Users/hessam/Documents/GitHub/Persian_Garden_Segmentation_Analysis/Data/mask\"\n",
    "\n",
    "image_files = sorted(os.listdir(IMAGE_DIR))\n",
    "mask_files = sorted(os.listdir(MASK_DIR))\n",
    "\n",
    "print(f\"Images: {len(image_files)}\")\n",
    "print(f\"Masks : {len(mask_files)}\")\n",
    "\n",
    "assert len(image_files) == len(mask_files), \"Imageâ€“mask count mismatch\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a0236c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Visual sanity check\u001b[39;00m\n\u001b[32m      2\u001b[39m idx = \u001b[32m0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m img = Image.open(os.path.join(IMAGE_DIR, \u001b[43mimage_files\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m)).convert(\u001b[33m\"\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m mask = Image.open(os.path.join(MASK_DIR, mask_files[idx])).convert(\u001b[33m\"\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m plt.figure(figsize=(\u001b[32m12\u001b[39m, \u001b[32m4\u001b[39m))\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Visual sanity check#Checking image-mask alignment and qualitzy by visualizing a sample pair. Adjust the index to view different pairs.\n",
    "\n",
    "idx = 0\n",
    "\n",
    "img = Image.open(os.path.join(IMAGE_DIR, image_files[idx])).convert(\"RGB\")\n",
    "mask = Image.open(os.path.join(MASK_DIR, mask_files[idx])).convert(\"RGB\")\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(mask)\n",
    "plt.title(\"RGB Mask\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(img)\n",
    "plt.imshow(mask, alpha=0.5)\n",
    "plt.title(\"Overlay\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab4a759b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Unique RGB colors\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m mask_np = np.array(\u001b[43mmask\u001b[49m)\n\u001b[32m      4\u001b[39m unique_colors = np.unique(mask_np.reshape(-\u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m), axis=\u001b[32m0\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mUnique RGB colors in this mask:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'mask' is not defined"
     ]
    }
   ],
   "source": [
    "# Unique RGB colors\n",
    "import numpy as np\n",
    "mask_np = np.array(mask)\n",
    "unique_colors = np.unique(mask_np.reshape(-1, 3), axis=0)\n",
    "\n",
    "print(\"Unique RGB colors in this mask:\")\n",
    "unique_colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757e6949",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m image_files = \u001b[38;5;28msorted\u001b[39m([\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m.listdir(IMAGE_DIR)\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m f.lower().endswith((\u001b[33m\"\u001b[39m\u001b[33m.png\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.jpg\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.jpeg\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m      4\u001b[39m ])\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTotal Images:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(image_files))\n",
      "\u001b[31mNameError\u001b[39m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# This reads all file names inside the folder.\n",
    "# We filter for common image formats and sort them to ensure consistent pairing with masks. The total count is printed to confirm the dataset size.\n",
    "image_files = sorted([\n",
    "    f for f in os.listdir(IMAGE_DIR)\n",
    "    if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "])\n",
    "\n",
    "print(\"Total Images:\", len(image_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5330eeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\"tree\", \"building\", \"sky\", \"water\", \"path\"]\n",
    "n_classes = len(CLASSES)\n",
    "# Map RGB to class index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f87ae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(CLASSES)\n",
    "# Define RGB to class index mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f12b3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First split test\n",
    "trainval_files, test_files = train_test_split(\n",
    "    image_files,\n",
    "    test_size=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Then split validation\n",
    "train_files, val_files = train_test_split(\n",
    "    trainval_files,\n",
    "    test_size=0.15,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train Size:\", len(train_files))\n",
    "print(\"Val Size  :\", len(val_files))\n",
    "print(\"Test Size :\", len(test_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7809e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a sample from the training set to confirm splits and data integrity. Adjust the index to view different samples.\n",
    "idx = 7  # or any number within range\n",
    "\n",
    "img_name = image_files[idx]\n",
    "\n",
    "img = Image.open(os.path.join(IMAGE_DIR, img_name)).convert(\"RGB\")\n",
    "mask = Image.open(os.path.join(MASK_DIR, img_name)).convert(\"RGB\")\n",
    "\n",
    "print(\"Image Size:\", np.array(img).shape)\n",
    "print(\"Mask Size :\", np.array(mask).shape)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(img)\n",
    "plt.imshow(mask, alpha=0.6)\n",
    "plt.title(\"Image with Mask Overlay\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981937a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, img_path, mask_path, file_list, color_map, mean, std, transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.mask_path = mask_path\n",
    "        self.files = file_list\n",
    "        self.transform = transform\n",
    "        self.color_map = color_map\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def rgb_to_class(self, mask):\n",
    "        h, w, _ = mask.shape\n",
    "        class_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "        \n",
    "        for rgb, class_id in self.color_map.items():\n",
    "            matches = np.all(mask == rgb, axis=-1)\n",
    "            class_mask[matches] = class_id\n",
    "            \n",
    "        return class_mask\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.files[idx]\n",
    "        \n",
    "        img = cv2.imread(self.img_path + img_name)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        mask = cv2.imread(self.mask_path + img_name)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            aug = self.transform(image=img, mask=mask)\n",
    "            img = aug['image']\n",
    "            mask = aug['mask']\n",
    "        \n",
    "        mask = self.rgb_to_class(mask)\n",
    "        \n",
    "        img = Image.fromarray(img)\n",
    "        t = T.Compose([\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(self.mean, self.std)\n",
    "        ])\n",
    "        img = t(img)\n",
    "        \n",
    "        mask = torch.from_numpy(mask).long()\n",
    "        \n",
    "        return img, mask"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
